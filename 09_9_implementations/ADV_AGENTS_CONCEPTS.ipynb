{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ Advanced Agents & MLOps implementations\n",
                "\n",
                "This notebook provides practical code implementations for the concepts discussed in the `150_ADV_AGENTS_MLOPS_EVALS.md` guide. We focus on implementable patterns while omitting purely architectural or infrastructure-based questions.\n",
                "\n",
                "## üõ† Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from typing import List, Dict, Any\n",
                "from dotenv import load_dotenv\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.messages import HumanMessage, SystemMessage\n",
                "\n",
                "load_dotenv()\n",
                "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
                "print(\"Setup Complete.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèóÔ∏è Section 1: Advanced RAG Patterns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q2: HyDE (Hypothetical Document Embeddings)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_hyde_document(query: str):\n",
                "    prompt = f\"Write a technical document that answers this query: {query}\"\n",
                "    hypothetical_doc = llm.invoke(prompt).content\n",
                "    print(f\"--- HYPOTHETICAL DOCUMENT ---\\n{hypothetical_doc[:150]}...\")\n",
                "    return hypothetical_doc\n",
                "\n",
                "hyde_doc = generate_hyde_document(\"How to optimize LLM inference?\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q7: Corrective RAG (CRAG)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def corrective_rag(query: str, retrieved_docs: List[str]):\n",
                "    evaluation_prompt = f\"Are these documents relevant to the query: '{query}'? Docs: {retrieved_docs}. Answer YES or NO.\"\n",
                "    relevancy = llm.invoke(evaluation_prompt).content.strip().upper()\n",
                "    \n",
                "    if 'YES' in relevancy:\n",
                "        print(\"‚úÖ Relevancy high. Using documents.\")\n",
                "        return \"AI Answer based on docs.\"\n",
                "    else:\n",
                "        print(\"‚ùå Relevancy low. Triggering fallback search.\")\n",
                "        return \"Fallback search result.\"\n",
                "\n",
                "print(corrective_rag(\"Apple M3\", [\"Cooking apples recipe\"]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q8: Self-RAG (Self-Grading)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def self_rag_agent(query: str):\n",
                "    prompt = f\"Answer the query. Append [SATISFACTORY] if sure, or [UNSURE] if you need more info. Query: {query}\"\n",
                "    return llm.invoke(prompt).content\n",
                "\n",
                "print(self_rag_agent(\"What is the capital of Mars?\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìà Section 2: Agent Evaluation (Evals)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q33: LLM-as-a-Judge"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def llm_judge(question: str, answer: str, ground_truth: str):\n",
                "    prompt = f\"Question: {question}\\nAnswer: {answer}\\nTruth: {ground_truth}\\nScore 1-10 and justify.\"\n",
                "    return llm.invoke(prompt).content\n",
                "\n",
                "print(llm_judge(\"What is 2+2?\", \"It is 5\", \"4\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ Section 3: MLOps & Versioning"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q70: Prompt Versioning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "registry = {\n",
                "    \"v1.0\": \"You are a helpful assistant.\",\n",
                "    \"v1.1\": \"You are a technical expert in Python.\"\n",
                "}\n",
                "def run_versioned(version: str, task: str):\n",
                "    return llm.invoke([SystemMessage(content=registry[version]), HumanMessage(content=task)]).content\n",
                "\n",
                "print(run_versioned(\"v1.1\", \"Explain decorators.\")[:50])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üõ†Ô∏è Section 4: Advanced Prompt Engineering"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q100: Chain of Verification (CoVe)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def cove_demo(query: str):\n",
                "    initial = llm.invoke(query).content\n",
                "    verification = llm.invoke(f\"Critique this for errors: {initial}\").content\n",
                "    final = llm.invoke(f\"Fix based on critique: {verification}. Original: {initial}\").content\n",
                "    return final\n",
                "\n",
                "print(cove_demo(\"When was the first iPhone released?\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üõ°Ô∏è Section 5: Security & Cost"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q127: Cost-per-Task (CPT)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def estimate_cost(input_tokens: int, output_tokens: int):\n",
                "    # GPT-4o-mini approx prices\n",
                "    return (input_tokens * 0.15 / 1e6) + (output_tokens * 0.60 / 1e6)\n",
                "\n",
                "print(f\"Task Cost: ${estimate_cost(1000, 500):.6f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Q129: Tool-use Safety (Read-only Guard)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def safe_db_exec(query: str):\n",
                "    if any(forbidden in query.upper() for forbidden in [\"DROP\", \"DELETE\", \"UPDATE\"]):\n",
                "        return \"ERROR: Write operation blocked.\"\n",
                "    return f\"SUCCESS: Selected data from query: {query}\"\n",
                "\n",
                "print(safe_db_exec(\"DELETE FROM users\"))\n",
                "print(safe_db_exec(\"SELECT * FROM users\"))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}