{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    " #from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",  # e.g., \"gpt-4o\", \"gpt-4o-mini\", \"omni-gpt-4\", \"omni-gpt-4-mini\"\n",
    "    # stream_usage=True,\n",
    "    temperature=0.0,\n",
    "    max_tokens=2000,\n",
    "    # timeout=None,\n",
    "    #reasoning_effort=\"low\",\n",
    "    # max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instead of using env vars\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# pip install langgraph langchain langchain-openai\n",
    "\n",
    "from typing import TypedDict, List, Annotated\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ============================\n",
    "# 1. Define the Agent State\n",
    "# ============================\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"State for our DeepAgent\"\"\"\n",
    "    messages: Annotated[List[str], operator.add]  # Conversation history\n",
    "    current_step: str                              # Current execution step\n",
    "    result: str                                    # Final result\n",
    "    max_iterations: int                            # Safety limit\n",
    "    iteration_count: int                           # Track iterations\n",
    "\n",
    "# ============================\n",
    "# 2. Define Node Functions\n",
    "# ============================\n",
    "def planner_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Planner: Decides what to do next\"\"\"\n",
    "    print(f\"ðŸ§  Planner Step {state['iteration_count'] + 1}\")\n",
    "    \n",
    "    # In a real implementation, this would use an LLM\n",
    "    # For this example, we'll use simple logic\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1] if messages else \"Start task\"\n",
    "    \n",
    "    if \"calculate\" in last_message.lower():\n",
    "        state['current_step'] = \"calculator\"\n",
    "    elif \"search\" in last_message.lower():\n",
    "        state['current_step'] = \"search\"\n",
    "    elif \"summarize\" in last_message.lower():\n",
    "        state['current_step'] = \"summarizer\"\n",
    "    else:\n",
    "        state['current_step'] = \"responder\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def calculator_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Calculator: Performs calculations\"\"\"\n",
    "    print(\"ðŸ§® Calculator executing...\")\n",
    "    last_message = state['messages'][-1]\n",
    "    \n",
    "    # Simple calculation extraction\n",
    "    if \"2+2\" in last_message:\n",
    "        state['result'] = \"The result of 2+2 is 4\"\n",
    "    elif \"10*5\" in last_message:\n",
    "        state['result'] = \"The result of 10*5 is 50\"\n",
    "    else:\n",
    "        state['result'] = \"I can perform simple calculations\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def search_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Search: Simulates information retrieval\"\"\"\n",
    "    print(\"ðŸ” Search executing...\")\n",
    "    query = state['messages'][-1]\n",
    "    state['result'] = f\"Search results for '{query}': [Result 1, Result 2, Result 3]\"\n",
    "    return state\n",
    "\n",
    "def summarizer_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Summarizer: Creates summaries\"\"\"\n",
    "    print(\"ðŸ“ Summarizer executing...\")\n",
    "    text = state['messages'][-1]\n",
    "    # Simple summary logic\n",
    "    words = text.split()\n",
    "    summary = ' '.join(words[:10]) + \"...\" if len(words) > 10 else text\n",
    "    state['result'] = f\"Summary: {summary}\"\n",
    "    return state\n",
    "\n",
    "def responder_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Responder: Generates final response\"\"\"\n",
    "    print(\"ðŸ’¬ Responder executing...\")\n",
    "    \n",
    "    if state.get('result'):\n",
    "        response = state['result']\n",
    "    else:\n",
    "        response = f\"I've completed step: {state['current_step']}\"\n",
    "    \n",
    "    state['messages'].append(f\"Agent: {response}\")\n",
    "    return state\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Router: Decides whether to continue or end\"\"\"\n",
    "    state['iteration_count'] += 1\n",
    "    \n",
    "    # Check if we have a result or hit max iterations\n",
    "    if state.get('result') or state['iteration_count'] >= state['max_iterations']:\n",
    "        return \"end\"\n",
    "    return \"continue\"\n",
    "\n",
    "# ============================\n",
    "# 3. Build the LangGraph\n",
    "# ============================\n",
    "def build_deep_agent_graph():\n",
    "    \"\"\"Builds the complete agent workflow graph\"\"\"\n",
    "    \n",
    "    # Create workflow builder\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"planner\", planner_node)\n",
    "    workflow.add_node(\"calculator\", calculator_node)\n",
    "    workflow.add_node(\"search\", search_node)\n",
    "    workflow.add_node(\"summarizer\", summarizer_node)\n",
    "    workflow.add_node(\"responder\", responder_node)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"planner\")\n",
    "    \n",
    "    # Define conditional edges from planner\n",
    "    workflow.add_conditional_edges(\n",
    "        \"planner\",\n",
    "        lambda state: state['current_step'],\n",
    "        {\n",
    "            \"calculator\": \"calculator\",\n",
    "            \"search\": \"search\", \n",
    "            \"summarizer\": \"summarizer\",\n",
    "            \"responder\": \"responder\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Add edges from action nodes to responder\n",
    "    workflow.add_edge(\"calculator\", \"responder\")\n",
    "    workflow.add_edge(\"search\", \"responder\")\n",
    "    workflow.add_edge(\"summarizer\", \"responder\")\n",
    "    \n",
    "    # Add conditional edge from responder\n",
    "    workflow.add_conditional_edges(\n",
    "        \"responder\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"continue\": \"planner\",\n",
    "            \"end\": END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Add memory for state persistence\n",
    "    memory = MemorySaver()\n",
    "    \n",
    "    # Compile the graph\n",
    "    app = workflow.compile(checkpointer=memory)\n",
    "    \n",
    "    return app\n",
    "\n",
    "# ============================\n",
    "# 4. Run the DeepAgent\n",
    "# ============================\n",
    "def run_deep_agent():\n",
    "    \"\"\"Execute the DeepAgent with different tasks\"\"\"\n",
    "    \n",
    "    # Build the agent graph\n",
    "    agent = build_deep_agent_graph()\n",
    "    \n",
    "    # Test cases\n",
    "    test_tasks = [\n",
    "        \"Calculate 2+2 for me\",\n",
    "        \"Search for information about AI\",\n",
    "        \"Summarize this long text about machine learning models\"\n",
    "    ]\n",
    "    \n",
    "    for task in test_tasks:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Task: {task}\")\n",
    "        print('='*50)\n",
    "        \n",
    "        # Initial state\n",
    "        initial_state = {\n",
    "            \"messages\": [f\"User: {task}\"],\n",
    "            \"current_step\": \"\",\n",
    "            \"result\": \"\",\n",
    "            \"max_iterations\": 5,\n",
    "            \"iteration_count\": 0\n",
    "        }\n",
    "        \n",
    "        # Execute the agent\n",
    "        config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "        final_state = agent.invoke(initial_state, config)\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nðŸ“Š Final Result: {final_state.get('result', 'No result')}\")\n",
    "        print(f\"ðŸ“ˆ Total Steps: {final_state['iteration_count']}\")\n",
    "        print(f\"ðŸ’­ Conversation History:\")\n",
    "        for msg in final_state['messages']:\n",
    "            print(f\"  - {msg}\")\n",
    "\n",
    "# ============================\n",
    "# 5. Advanced: LLM-Powered Version\n",
    "# ============================\n",
    "class LLMDeepAgent:\n",
    "    \"\"\"More advanced version using actual LLMs\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"gpt-3.5-turbo\"):\n",
    "        self.llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "        self.graph = self._build_llm_graph()\n",
    "    \n",
    "    def _build_llm_graph(self):\n",
    "        \"\"\"Build graph with LLM-based decision making\"\"\"\n",
    "        \n",
    "        def llm_planner(state):\n",
    "            \"\"\"Use LLM to decide next step\"\"\"\n",
    "            prompt = f\"\"\"\n",
    "            Based on the conversation, decide the next action:\n",
    "            Conversation: {state['messages']}\n",
    "            \n",
    "            Choose from: [calculator, search, summarizer, responder, end]\n",
    "            \n",
    "            Return only the action name.\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.llm.invoke(prompt)\n",
    "            state['current_step'] = response.content.strip().lower()\n",
    "            return state\n",
    "        \n",
    "        # Similar graph structure but with LLM planner\n",
    "        workflow = StateGraph(AgentState)\n",
    "        workflow.add_node(\"planner\", llm_planner)\n",
    "        # ... add other nodes as before\n",
    "        \n",
    "        return workflow.compile()\n",
    "\n",
    "# ============================\n",
    "# 6. Main Execution\n",
    "# ============================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸš€ LangGraph DeepAgent Demonstration\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Run the basic agent\n",
    "    run_deep_agent()\n",
    "    \n",
    "    print(\"\\n\\nðŸ”§ Key Concepts Demonstrated:\")\n",
    "    print(\"1. State Management: TypedDict for agent state\")\n",
    "    print(\"2. Node Functions: Specialized components\")\n",
    "    print(\"3. Conditional Routing: Dynamic workflow paths\")\n",
    "    print(\"4. Memory/Checkpoints: State persistence\")\n",
    "    print(\"5. Iterative Processing: Multiple reasoning steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fd661",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
