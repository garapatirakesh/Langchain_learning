{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b223c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a624c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    " #from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d88bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",  # e.g., \"gpt-4o\", \"gpt-4o-mini\", \"omni-gpt-4\", \"omni-gpt-4-mini\"\n",
    "    # stream_usage=True,\n",
    "    temperature=0.0,\n",
    "    max_tokens=2000,\n",
    "    # timeout=None,\n",
    "    #reasoning_effort=\"low\",\n",
    "    # max_retries=2,\n",
    "    # api_key=\"...\",  # if you prefer to pass api key in directly instead of using env vars\n",
    "    # base_url=\"...\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "LangGraph: COMPLEX RIVER CROSSING PUZZLE\n",
    "SAME HARD TASK â†’ 4 AGENTS FAIL/SUCCEED DIFFERENTLY\n",
    "Task: Cabbage/Goat/Lion puzzle (ReAct+Reflection FAIL, Reflexion+Tree SUCCEED)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import Annotated, Dict, List, Literal\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "# # COMPLEX PUZZLE (Designed to TRICK simple agents)\n",
    "# PUZZLE = \"\"\"Suppose I have a cabbage, a goat and a lion, and I need to get them across a river. \n",
    "# I have a boat that can only carry myself and a single other item. \n",
    "# I am not allowed to leave the cabbage and lion alone together, \n",
    "# and I am not allowed to leave the lion and goat alone together. \n",
    "# How can I safely get all three across?\"\"\"\n",
    "\n",
    "# CORRECT_SOLUTION = \"\"\"\n",
    "# 1. Take lion across (leave goat+cabbage)\n",
    "# 2. Return alone  \n",
    "# 3. Take cabbage across (leave goat alone)  \n",
    "# 4. Bring lion back (leave cabbage alone)\n",
    "# 5. Take goat across (leave lion alone)\n",
    "# 6. Return alone\n",
    "# 7. Take lion across âœ“\n",
    "#\"\"\"\n",
    "\n",
    "PUZZLE = \"\"\"pick two random 5 digit numbers and multiply them together\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# ðŸŽ® 1. REAct AGENT (FAILS - Single pass can't solve complex planning)\n",
    "# =============================================================================\n",
    "def react_node(state: Dict) -> Dict:\n",
    "    prompt = f\"\"\"ReAct Agent (1 step): {PUZZLE}\n",
    "\n",
    "Thought: [brief reasoning]\n",
    "Action: [solution sequence]\"\"\"\n",
    "    msg = llm.invoke([HumanMessage(content=prompt)])\n",
    "    result = msg.content\n",
    "    # ReAct FAILS: Misses full sequence\n",
    "    #return {\"result\": result, \"status\": \"âŒ FAILED (incomplete)\", \"messages\": [AIMessage(\"ðŸŽ® ReAct: 1 step FAIL\")]}\n",
    "    return result\n",
    "\n",
    "react_graph = StateGraph(dict)\n",
    "react_graph.add_node(\"react\", react_node)\n",
    "react_graph.add_edge(START, \"react\")\n",
    "react_graph.add_edge(\"react\", END)\n",
    "REACT_AGENT = react_graph.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f17b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(REACT_AGENT.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64c3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸŽ® 1. REAct Agent\")\n",
    "print(\"-\" * 40)\n",
    "react_result = REACT_AGENT.invoke({\"task\": PUZZLE})\n",
    "print(f\"   {react_result}\")\n",
    "#print(f\"   Output: {react_result['result']}...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ðŸªž 2. REFLECTION AGENT (FAILS - 1 reflection not enough for 7-step puzzle)\n",
    "# =============================================================================\n",
    "def reflection_generate(state: Dict) -> Dict:\n",
    "    msg = llm.invoke([HumanMessage(content=f\"Solve: {PUZZLE}\")])\n",
    "    print(msg.content)\n",
    "    return {\"attempt\": msg.content}\n",
    "\n",
    "def reflection_critique(state: Dict) -> Dict:\n",
    "    critique = llm.invoke([HumanMessage(f\"CRITIQUE: {PUZZLE}\\nAttempt: {state['attempt']}\\ is the solution correct?\")])\n",
    "    return {\"critique\": critique.content}\n",
    "\n",
    "def reflection_fix(state: Dict) -> Dict:\n",
    "    # Still fails - 1 reflection can't solve complex constraint puzzle\n",
    "    prompt = f\"Fix: {PUZZLE}\\nOld: \\nCritique: {state['critique']}\\nFIXED:\"\n",
    "    msg = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return msg\n",
    "\n",
    "reflection_graph = StateGraph(dict)\n",
    "reflection_graph.add_node(\"generate\", reflection_generate)\n",
    "reflection_graph.add_node(\"critique\", reflection_critique) \n",
    "reflection_graph.add_node(\"fix\", reflection_fix)\n",
    "reflection_graph.add_edge(START, \"generate\")\n",
    "reflection_graph.add_edge(\"generate\", \"critique\")\n",
    "reflection_graph.add_edge(\"critique\", \"fix\")\n",
    "reflection_graph.add_edge(\"fix\", END)\n",
    "REFLECTION_AGENT = reflection_graph.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b084605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(REFLECTION_AGENT.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸªž 2. Reflection Agent\") \n",
    "print(\"-\" * 40)\n",
    "reflection_result = REFLECTION_AGENT.invoke({\"task\": PUZZLE})\n",
    "print(f\"   Output: {reflection_result.content}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dada792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ðŸ”„ 3. REFLEXION AGENT (SUCCEEDS - Multiple iterations learn constraints)\n",
    "# =============================================================================\n",
    "class ReflexionState(TypedDict):\n",
    "    task: str\n",
    "    attempts: List[str]\n",
    "    reflections: List[str]\n",
    "    iteration: int\n",
    "    result: str\n",
    "\n",
    "def reflexion_act(state: ReflexionState) -> Dict:\n",
    "    iteration = state.get(\"iteration\", 0)\n",
    "    context = \"\\n\".join(state[\"reflections\"][-2:]) if state[\"reflections\"] else \"\"\n",
    "    prompt = f\"Reflexion #{iteration+1}: {state['task']}\\nPast: {context}\\nNEW ATTEMPT:\"\n",
    "    msg = llm.invoke([HumanMessage(content=prompt)])\n",
    "    print(msg.content)\n",
    "    return {\"attempts\": state[\"attempts\"] + [msg.content], \"iteration\": iteration + 1}\n",
    "\n",
    "def reflexion_reflect(state: ReflexionState) -> Dict:\n",
    "    latest = state[\"attempts\"][-1]\n",
    "    reflection = llm.invoke([HumanMessage(f\"{state['task']}\\nAttempt: {latest}\\nREFLECT: correct output?\")])\n",
    "    return {\"reflections\": state[\"reflections\"] + [reflection.content]}\n",
    "\n",
    "def reflexion_continue(state: ReflexionState) -> Literal[\"reflect\", \"end\"]:\n",
    "    return \"end\" if state[\"iteration\"] >= 4 else \"reflect\"  # More iterations needed\n",
    "\n",
    "reflexion_graph = StateGraph(ReflexionState)\n",
    "reflexion_graph.add_node(\"act\", reflexion_act)\n",
    "reflexion_graph.add_node(\"reflect\", reflexion_reflect)\n",
    "reflexion_graph.add_edge(START, \"act\")\n",
    "reflexion_graph.add_conditional_edges(\"act\", reflexion_continue, {\"reflect\": \"reflect\", \"end\": END})\n",
    "reflexion_graph.add_edge(\"reflect\", \"act\")\n",
    "REFLEXION_AGENT = reflexion_graph.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cde47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ”„ 3. Reflexion Agent\")\n",
    "print(\"-\" * 40)\n",
    "reflexion_result = REFLEXION_AGENT.invoke({\n",
    "        \"task\": PUZZLE, \"attempts\": [], \"reflections\": [], \"iteration\": 0, \"result\": \"\"\n",
    "    })\n",
    "print(f\"   Output: {reflexion_result['reflections']}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7812ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ðŸŒ³ 4. TREE SEARCH AGENT (SUCCEEDS - Systematic constraint checking)\n",
    "# =============================================================================\n",
    "def tree_explore(state: Dict) -> Dict:\n",
    "    prompt = f\"Tree Search: {PUZZLE}\\nGenerate 4 complete crossing sequences checking ALL constraints each step.\"\n",
    "    msg = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {\"paths\": msg.content}\n",
    "\n",
    "def tree_evaluate(state: Dict) -> Dict:\n",
    "    prompt = f\"Evaluate: {PUZZLE}\\nPaths: {state['paths']}\\nWhich satisfies ALL constraints? BEST SEQUENCE:\"\n",
    "    msg = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {\"result\": msg.content, \"status\": \"âœ… SUCCESS (systematic)\"}\n",
    "\n",
    "tree_graph = StateGraph(dict)\n",
    "tree_graph.add_node(\"explore\", tree_explore)\n",
    "tree_graph.add_node(\"evaluate\", tree_evaluate)\n",
    "tree_graph.add_edge(START, \"explore\")\n",
    "tree_graph.add_edge(\"explore\", \"evaluate\")\n",
    "tree_graph.add_edge(\"evaluate\", END)\n",
    "TREE_AGENT = tree_graph.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b9960",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸŒ³ 4. Tree Search Agent\")\n",
    "print(\"-\" * 40)\n",
    "tree_result = TREE_AGENT.invoke({\"task\": PUZZLE})\n",
    "print(f\"   {tree_result['status']}\")\n",
    "print(f\"   Output: {tree_result['result']}...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920347d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "FIXED LangGraph REFLECTION Agent: Multiply 2 RANDOM 5-digit numbers\n",
    "âœ… Handles commas in numbers (ValueError fix)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from typing import Annotated, Dict, List, Literal\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Setup\n",
    "\n",
    "# Generate RANDOM 5-digit numbers\n",
    "num1 = random.randint(10000, 99999)\n",
    "num2 = random.randint(10000, 99999)\n",
    "CORRECT_ANSWER = num1 * num2\n",
    "TASK = f\"Multiply {num1} Ã— {num2} = ? (Give exact answer)\"\n",
    "\n",
    "print(f\"ðŸ”¢ Numbers: {num1} Ã— {num2}\")\n",
    "print(f\"âœ… Correct: {CORRECT_ANSWER:,}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# âœ… FIXED: Clean number extraction (handles commas/spaces)\n",
    "def clean_number(text: str) -> int:\n",
    "    \"\"\"Extract & clean number from LLM output (handles 919,999,296 â†’ 919999296)\"\"\"\n",
    "    # Remove commas, spaces, $ signs, etc.\n",
    "    cleaned = re.sub(r'[^\\d]', '', str(text))\n",
    "    return int(cleaned) if cleaned.isdigit() else 0\n",
    "\n",
    "# =============================================================================\n",
    "# REFLECTION STATE\n",
    "# =============================================================================\n",
    "class ReflectionState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    task: str\n",
    "    attempts: List[str]\n",
    "    critiques: List[str]\n",
    "    iteration: int\n",
    "    final_answer: str\n",
    "    is_correct: bool\n",
    "\n",
    "# =============================================================================\n",
    "# FIXED NODES\n",
    "# =============================================================================\n",
    "def generate_attempt(state: ReflectionState) -> Dict:\n",
    "    iteration = state.get(\"iteration\", 0)\n",
    "    past_critiques = \"\\n\".join(state[\"critiques\"][-2:]) if state[\"critiques\"] else \"No critiques\"\n",
    "    \n",
    "    prompt = f\"\"\"MULTIPLICATION TASK (Iteration {iteration + 1}): {state['task']}\n",
    "\n",
    "Past critiques:\n",
    "{past_critiques}\n",
    "\n",
    "CALCULATE EXACTLY: {num1} Ã— {num2} = ?\n",
    "\n",
    "ONLY the number (no commas needed):\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    attempt = response.content.strip()\n",
    "    \n",
    "    print(f\"  ðŸ“ Attempt #{iteration + 1}: {attempt}\")\n",
    "    return {\n",
    "        \"attempts\": state[\"attempts\"] + [attempt],\n",
    "        \"iteration\": iteration + 1,\n",
    "        \"messages\": [AIMessage(content=f\"Generated attempt #{iteration + 1}\")]\n",
    "    }\n",
    "\n",
    "def critique_attempt(state: ReflectionState) -> Dict:\n",
    "    latest_attempt = state[\"attempts\"][-1]\n",
    "    \n",
    "    # âœ… FIXED: Use clean_number() to handle commas\n",
    "    attempt_num = clean_number(latest_attempt)\n",
    "    correct_num = CORRECT_ANSWER\n",
    "    \n",
    "    is_correct = abs(attempt_num - correct_num) <= 1  # Allow tiny rounding errors\n",
    "    \n",
    "    prompt = f\"\"\"CRITIQUE this multiplication:\n",
    "{state['task']}\n",
    "Attempt: {latest_attempt} â†’ {attempt_num:,}\n",
    "Correct: {correct_num:,}\n",
    "\n",
    "Is it CORRECT? (Y/N)\n",
    "ERROR: {'CORRECT' if is_correct else f'WRONG! Off by {correct_num - attempt_num:,}'}\n",
    "IMPROVEMENT:\"\"\"\n",
    "    \n",
    "    critique = llm.invoke([HumanMessage(content=prompt)])\n",
    "    critique_text = critique.content.strip()\n",
    "    \n",
    "    print(f\"  ðŸ§ Attempt value: {attempt_num:,}\")\n",
    "    print(f\"  âœ… Correct? {'YES' if is_correct else 'NO'}\")\n",
    "    print(f\"  ðŸ“Š Error: {correct_num - attempt_num:,}\")\n",
    "    \n",
    "    return {\n",
    "        \"critiques\": state[\"critiques\"] + [critique_text],\n",
    "        \"is_correct\": is_correct,\n",
    "        \"messages\": [AIMessage(content=\"Critique complete\")]\n",
    "    }\n",
    "\n",
    "def should_continue(state: ReflectionState) -> Literal[\"continue\", \"end\"]:\n",
    "    max_iterations = 5\n",
    "    return \"end\" if state[\"is_correct\"] or state[\"iteration\"] >= max_iterations else \"continue\"\n",
    "\n",
    "def finalize(state: ReflectionState) -> Dict:\n",
    "    final = state[\"attempts\"][-1]\n",
    "    final_num = clean_number(final)\n",
    "    print(f\"\\nðŸŽ¯ FINAL RESULT: {final} â†’ {final_num:,}\")\n",
    "    print(f\"âœ… VERIFIED: {'CORRECT âœ“' if state['is_correct'] else 'INCORRECT âœ—'}\")\n",
    "    print(f\"ðŸ“Š Iterations: {state['iteration']}\")\n",
    "    print(f\"ðŸ” Critiques: {len(state['critiques'])}\")\n",
    "    \n",
    "    return {\n",
    "        \"final_answer\": final,\n",
    "        \"messages\": [AIMessage(content=f\"FINAL: {final_num:,} ({'âœ“' if state['is_correct'] else 'âœ—'})\")]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# BUILD GRAPH\n",
    "# =============================================================================\n",
    "workflow = StateGraph(ReflectionState)\n",
    "workflow.add_node(\"generate\", generate_attempt)\n",
    "workflow.add_node(\"critique\", critique_attempt)\n",
    "workflow.add_node(\"finalize\", finalize)\n",
    "\n",
    "workflow.add_edge(START, \"generate\")\n",
    "workflow.add_conditional_edges(\"generate\", should_continue, {\"continue\": \"critique\", \"end\": \"finalize\"})\n",
    "workflow.add_edge(\"critique\", \"generate\")\n",
    "workflow.add_edge(\"finalize\", END)\n",
    "\n",
    "reflection_agent = workflow.compile()\n",
    "\n",
    "# =============================================================================\n",
    "# RUN\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸ¤– FIXED REFLECTION AGENT - NO MORE ValueError!\")\n",
    "    print(f\"TASK: {TASK}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    result = reflection_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=TASK)],\n",
    "        \"task\": TASK,\n",
    "        \"attempts\": [],\n",
    "        \"critiques\": [],\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": \"\",\n",
    "        \"is_correct\": False\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸŽ‰ REFLECTION COMPLETE!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(reflection_agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35729b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "LangGraph REFLEXION Agent: Multiply 2 RANDOM 5-digit numbers\n",
    "ACT â†’ REFLECT â†’ ACT â†’ REFLECT â†’ ... (Verbal Reinforcement Learning)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from typing import Annotated, Dict, List, Literal\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Setup\n",
    "\n",
    "# Generate RANDOM 5-digit numbers\n",
    "num1 = random.randint(10000, 99999)\n",
    "num2 = random.randint(10000, 99999)\n",
    "CORRECT_ANSWER = num1 * num2\n",
    "TASK = f\"Multiply {num1} Ã— {num2} = ? (Give exact answer)\"\n",
    "\n",
    "print(f\"ðŸ”¢ Numbers: {num1} Ã— {num2}\")\n",
    "print(f\"âœ… Correct: {CORRECT_ANSWER:,}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Clean number extraction (handles commas)\n",
    "def clean_number(text: str) -> int:\n",
    "    cleaned = re.sub(r'[^\\d]', '', str(text))\n",
    "    return int(cleaned) if cleaned.isdigit() else 0\n",
    "\n",
    "# =============================================================================\n",
    "# REFLEXION STATE (Tracks verbal self-improvement)\n",
    "# =============================================================================\n",
    "class ReflexionState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    task: str\n",
    "    trajectory: List[str]      # All attempts (ACT steps)\n",
    "    reflections: List[str]     # Verbal self-critiques\n",
    "    iteration: int\n",
    "    final_answer: str\n",
    "    is_correct: bool\n",
    "\n",
    "# =============================================================================\n",
    "# REFLEXION NODES (ACT â†’ REFLECT loop)\n",
    "# =============================================================================\n",
    "def act_node(state: ReflexionState) -> Dict:\n",
    "    \"\"\"ACT: Generate next trajectory/attempt\"\"\"\n",
    "    iteration = state.get(\"iteration\", 0)\n",
    "    \n",
    "    # Verbal context from past reflections (key Reflexion feature)\n",
    "    reflection_context = \"\\n\".join([f\"R{i+1}: {r[:80]}...\" for i, r in enumerate(state[\"reflections\"][-3:])])\n",
    "    \n",
    "    prompt = f\"\"\"REFLEXION AGENT - ITERATION #{iteration + 1}\n",
    "TASK: {state['task']}\n",
    "\n",
    "VERBAL SELF-REFLECTIONS (learn from mistakes):\n",
    "{reflection_context if reflection_context else 'No reflections yet'}\n",
    "\n",
    "ACT: Generate your BEST trajectory/calculation now.\n",
    "Give ONLY the final number:\"\"\"\n",
    "    \n",
    "    response = llm.invoke([HumanMessage(content=prompt)])\n",
    "    trajectory = response.content.strip()\n",
    "    \n",
    "    print(f\"  ðŸŽ¯ ACT #{iteration + 1}: {trajectory}\")\n",
    "    return {\n",
    "        \"trajectory\": state[\"trajectory\"] + [trajectory],\n",
    "        \"iteration\": iteration + 1,\n",
    "        \"messages\": [AIMessage(content=f\"ACT #{iteration + 1}: {trajectory}\")]\n",
    "    }\n",
    "\n",
    "def reflect_node(state: ReflexionState) -> Dict:\n",
    "    \"\"\"REFLECT: Verbal self-critique (core Reflexion mechanism)\"\"\"\n",
    "    latest_trajectory = state[\"trajectory\"][-1]\n",
    "    attempt_num = clean_number(latest_trajectory)\n",
    "    correct_num = CORRECT_ANSWER\n",
    "    is_correct = abs(attempt_num - correct_num) <= 1\n",
    "    \n",
    "    prompt = f\"\"\"REFLEXION: Verbal Self-Critique\n",
    "TASK: {state['task']}\n",
    "LATEST TRAJECTORY: {latest_trajectory} â†’ {attempt_num:,}\n",
    "CORRECT: {correct_num:,}\n",
    "\n",
    "VERBAL REFLECTION:\n",
    "1. Was this CORRECT? {is_correct}\n",
    "2. What went WRONG? (digit errors, carrying mistakes, etc.)\n",
    "3. How to IMPROVE next time?\n",
    "\n",
    "Be VERBAL and SPECIFIC about calculation errors:\"\"\"\n",
    "    \n",
    "    reflection = llm.invoke([HumanMessage(content=prompt)])\n",
    "    reflection_text = reflection.content.strip()\n",
    "    \n",
    "    print(f\"  ðŸ§  REFLECT #{len(state['reflections']) + 1}: {reflection_text[:100]}...\")\n",
    "    print(f\"  âœ… Correct so far? {'YES' if is_correct else 'NO'}\")\n",
    "    \n",
    "    return {\n",
    "        \"reflections\": state[\"reflections\"] + [reflection_text],\n",
    "        \"is_correct\": is_correct,\n",
    "        \"messages\": [AIMessage(content=\"REFLECT: Verbal self-improvement\")]\n",
    "    }\n",
    "\n",
    "def should_continue(state: ReflexionState) -> Literal[\"reflect\", \"end\"]:\n",
    "    \"\"\"Continue reflexion until correct OR max iterations\"\"\"\n",
    "    max_iterations = 6\n",
    "    return \"end\" if state[\"is_correct\"] or state[\"iteration\"] >= max_iterations else \"reflect\"\n",
    "\n",
    "def finalize_node(state: ReflexionState) -> Dict:\n",
    "    \"\"\"Finalize with complete Reflexion trace\"\"\"\n",
    "    final_trajectory = state[\"trajectory\"][-1]\n",
    "    final_num = clean_number(final_trajectory)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸŽ¯ REFLEXION COMPLETE - VERBAL REINFORCEMENT LEARNING\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"TASK: {state['task']}\")\n",
    "    print(f\"FINAL: {final_trajectory} â†’ {final_num:,}\")\n",
    "    print(f\"âœ… STATUS: {'CORRECT âœ“' if state['is_correct'] else 'INCORRECT âœ—'}\")\n",
    "    print(f\"ðŸ“ˆ Iterations: {state['iteration']}\")\n",
    "    print(f\"ðŸ§  Reflections: {len(state['reflections'])}\")\n",
    "    print(\"\\nðŸ“œ REFLEXION TRACE:\")\n",
    "    for i, (traj, refl) in enumerate(zip(state[\"trajectory\"][-3:], state[\"reflections\"][-3:]), 1):\n",
    "        print(f\"  {i}. ACT: {traj[:40]}... â†’ REFLECT: {refl[:60]}...\")\n",
    "    \n",
    "    return {\n",
    "        \"final_answer\": final_trajectory,\n",
    "        \"messages\": [AIMessage(content=f\"REFLEXION SUCCESS: {final_num:,}\")]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# BUILD REFLEXION GRAPH\n",
    "# =============================================================================\n",
    "workflow = StateGraph(ReflexionState)\n",
    "\n",
    "workflow.add_node(\"act\", act_node)\n",
    "workflow.add_node(\"reflect\", reflect_node)\n",
    "workflow.add_node(\"finalize\", finalize_node)\n",
    "\n",
    "# Reflexion loop: ACT â†’ REFLECT â†’ ACT â†’ ...\n",
    "workflow.add_edge(START, \"act\")\n",
    "workflow.add_conditional_edges(\"act\", should_continue, {\"reflect\": \"reflect\", \"end\": \"finalize\"})\n",
    "workflow.add_edge(\"reflect\", \"act\")\n",
    "workflow.add_edge(\"finalize\", END)\n",
    "\n",
    "reflexion_agent = workflow.compile()\n",
    "\n",
    "# =============================================================================\n",
    "# RUN REFLEXION AGENT\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸ”„ REFLEXION AGENT: Verbal Reinforcement Learning\")\n",
    "    print(f\"TASK: {TASK}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    result = reflexion_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=TASK)],\n",
    "        \"task\": TASK,\n",
    "        \"trajectory\": [],\n",
    "        \"reflections\": [],\n",
    "        \"iteration\": 0,\n",
    "        \"final_answer\": \"\",\n",
    "        \"is_correct\": False\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(reflexion_agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
