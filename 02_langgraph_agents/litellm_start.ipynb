{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843147ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd48eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "import os\n",
    "\n",
    "\n",
    "openaillm = completion(\n",
    "  model=\"openai/gpt-4o\",\n",
    "  messages=[{ \"content\": \"Hello, how are you?\",\"role\": \"user\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0bc660",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(openaillm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bde4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import acompletion\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def test_get_response():\n",
    "    user_message = \"Hello, how are you?\"\n",
    "    messages = [{\"content\": user_message, \"role\": \"user\"}]\n",
    "    response = await acompletion(model=\"openai/gpt-4o\", messages=messages)\n",
    "    return response\n",
    "\n",
    "response = asyncio.run(test_get_response())\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24db9e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from litellm import acompletion\n",
    "import asyncio\n",
    "\n",
    "async def test_get_response():\n",
    "    user_message = \"Hello, how are you?\"\n",
    "    messages = [{\"content\": user_message, \"role\": \"user\"}]\n",
    "    response = await acompletion(model=\"openai/gpt-4o\", messages=messages)\n",
    "    return response\n",
    "\n",
    "response = await test_get_response()\n",
    "print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio; nest_asyncio.apply()\n",
    "response2 = asyncio.run(test_get_response())\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3b8f9",
   "metadata": {},
   "source": [
    "### Quick summary\n",
    "\n",
    "Top-level await: Jupyter/IPython kernels support awaiting coroutines directly in cells (preferred).\n",
    "Problem: asyncio.run() raises RuntimeError if an event loop is already running (common in notebooks).\n",
    "Fix: either use top-level await, or install/apply nest_asyncio to allow asyncio.run inside a running loop.\n",
    "Install & use nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fef44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: top-level await in a notebook cell\n",
    "from litellm import acompletion\n",
    "\n",
    "async def test_get_response():\n",
    "    msgs = [{\"content\": \"Hello, how are you?\", \"role\": \"user\"}]\n",
    "    return await acompletion(model=\"openai/gpt-4o\", messages=msgs)\n",
    "\n",
    "# In a notebook cell that supports top-level await:\n",
    "resp = await test_get_response()\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b56861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install once:\n",
    "#!pip install nest_asyncio\n",
    "\n",
    "# Then in a notebook cell:\n",
    "import nest_asyncio, asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from litellm import acompletion\n",
    "\n",
    "async def test_get_response():\n",
    "    msgs = [{\"content\": \"Hello, how are you?\", \"role\": \"user\"}]\n",
    "    return await acompletion(model=\"openai/gpt-4o\", messages=msgs)\n",
    "\n",
    "# Now asyncio.run will not raise RuntimeError\n",
    "resp = asyncio.run(test_get_response())\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7250175",
   "metadata": {},
   "source": [
    "# LITE LLM PROXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd5ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install litellm[proxy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea07d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install presidio_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb8c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_analyzer.nlp_engine import SpacyNlpEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "\n",
    "# Configuration for the NLP engine\n",
    "configuration = {\n",
    "    \"nlp_engine_name\": \"spacy\",\n",
    "    \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\"}]\n",
    "}\n",
    "\n",
    "# Create NLP engine\n",
    "provider = NlpEngineProvider(nlp_configuration=configuration)\n",
    "nlp_engine = provider.create_engine()\n",
    "\n",
    "# Plug NLP engine into Analyzer\n",
    "analyzer = AnalyzerEngine(nlp_engine=nlp_engine, supported_languages=[\"en\"])\n",
    "\n",
    "# Test input\n",
    "text = \"My name is Rakesh garapati  and my email is rakesh@example.com and PAN is xxxx-xxxx-xxxx 49296919 26368685\"\n",
    "results = analyzer.analyze(text=text, entities=[], language=\"en\")\n",
    "\n",
    "print(\"Analysis complete. \", results)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"{result.entity_type}: {text[result.start:result.end]} (score={result.score:.2f})\")\n",
    "\n",
    "#print(\"Analysis complete. \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e867163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ranges from end->start to avoid index shifts and wrap with tags\n",
    "tagged = text\n",
    "for r in sorted(results, key=lambda x: x.start, reverse=True):\n",
    "    start, end = r.start, r.end\n",
    "    tag = r.entity_type  # e.g. \"PERSON\" or \"EMAIL_ADDRESS\"\n",
    "    tagged = tagged[:start] + f\"<{tag}> </{tag}> \" + tagged[end:]\n",
    "\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd717786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "\n",
    "ANALYZER = os.environ.get(\"PRESIDIO_ANALYZER_API_BASE\", \"http://127.0.0.1:5002\")\n",
    "ANONYMIZER = os.environ.get(\"PRESIDIO_ANONYMIZER_API_BASE\", \"http://127.0.0.1:5001\")\n",
    "text = \"My name is John Doe and my email is john@example.com\"\n",
    "\n",
    "# 1) Analyze\n",
    "a_resp = requests.post(f\"http://127.0.0.1:5002/analyze\", json={\"text\": text, \"language\": \"en\"}, timeout=30)\n",
    "a_resp.raise_for_status()\n",
    "results = a_resp.json()  # list of detection results\n",
    "\n",
    "# Convert detections to anonymizer entities and build anonymizers_config (mask each detected type)\n",
    "entities = [{\"start\": r[\"start\"], \"end\": r[\"end\"], \"entity_type\": r.get(\"entity_type\", r.get(\"type\"))} for r in results]\n",
    "anonymizers_config = {e[\"entity_type\"]: {\"type\": \"mask\", \"masking_char\": \"*\"} for e in entities}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Anonymizers config:\", anonymizers_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c11baf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e504cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Anonymize\n",
    "payload = {\n",
    "    \"text\": text,\n",
    "    \"entities\": entities,\n",
    "    \"analyzer_results\": results,  \n",
    "    \"anonymizers_config\": anonymizers_config,\n",
    "}\n",
    "anon_resp = requests.post(f\"{ANONYMIZER}/anonymize\", json=payload, timeout=30)\n",
    "anon_resp.raise_for_status()\n",
    "print(anon_resp.json().get(\"text\") or anon_resp.json())  # masked text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3673674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Start litellm proxy\n",
    "#$ litellm --model huggingface/bigcode/starcoder\n",
    "#$ litellm --model openai/gpt-4o\n",
    "\n",
    "#INFO: Proxy running on http://0.0.0.0:4000\n",
    "\n",
    "\n",
    "#https://genai.owasp.org/llm-top-10/\n",
    "\n",
    "#\"Input should be \n",
    "# 'CREDIT_CARD', 'CRYPTO', 'DATE_TIME', 'EMAIL_ADDRESS', 'IBAN_CODE', 'IP_ADDRESS', 'NRP', \n",
    "# 'LOCATION', 'PERSON', 'PHONE_NUMBER', 'MEDICAL_LICENSE', 'URL', 'US_BANK_NUMBER', 'US_DRIVER_LICENSE', \n",
    "# 'US_ITIN', 'US_PASSPORT', 'US_SSN', 'UK_NHS', 'UK_NINO', 'ES_NIF', 'ES_NIE', 'IT_FISCAL_CODE', \n",
    "# 'IT_DRIVER_LICENSE', 'IT_VAT_CODE', 'IT_PASSPORT', 'IT_IDENTITY_CARD', 'PL_PESEL', 'SG_NRIC_FIN', \n",
    "# 'SG_UEN', 'AU_ABN', 'AU_ACN', 'AU_TFN', 'AU_MEDICARE', 'IN_PAN', 'IN_AADHAAR', \n",
    "# 'IN_VEHICLE_REGISTRATION', 'IN_VOTER', 'IN_PASSPORT' or 'FI_PERSONAL_IDENTITY_CODE'\",\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cacc4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6001f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm --config config.yaml --detailed_debug\n",
    "\n",
    "curl -v http://127.0.0.1:4000/health\n",
    "curl -v http://127.0.0.1:4000/docs   # FastAPI docs, if enabled\n",
    "curl -v http://127.0.0.1:4000/v1/models\n",
    "\n",
    "  ```bash\n",
    "    curl -X GET \"http://localhost:4000/guardrails/list\" -H \"Authorization: Bearer <your_api_key>\"\n",
    "    ```\n",
    "\n",
    "\n",
    "OPENAI_API_KEY=\"sk-REPLACE_WITH_NEW_KEY\"\n",
    "LANGCHAIN_API_KEY=\"lsv2_REPLACE_WITH_NEW_KEY\"\n",
    "# Set Presidio analyzer URL (map to container port on host)\n",
    "PRESIDIO_ANALYZER_API_BASE=\"http://127.0.0.1:3000\"\n",
    "# optional if your deploy requires an API key\n",
    "PRESIDIO_ANALYZER_API_KEY=\"replace_if_required\"\n",
    "\n",
    "\n",
    "curl.exe http://127.0.0.1:4000/health\n",
    "curl.exe -H \"Authorization: Bearer $env:OPENAI_API_KEY\" http://127.0.0.1:4000/guardrails/list\n",
    "\n",
    "# apply guardrail (example)\n",
    "curl.exe -X POST \"http://127.0.0.1:4000/guardrails/apply_guardrail\" `\n",
    "  -H \"Content-Type: application/json\" `\n",
    "  -H \"Authorization: Bearer $env:OPENAI_API_KEY\" `\n",
    "  -d '{\"guardrail_name\":\"presidio-pii\",\"text\":\"My name is John Doe and my email is john@example.com\",\"language\":\"en\",\"entities\":[\"NAME\",\"EMAIL\"]}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd78e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://localhost:4000/v1/chat/completions\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"model\": \"gpt-3.5-turbo\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"hi my email is ishaan@berri.ai , what is my email? and tell me a joke\"\n",
    "    }\n",
    "  ],\n",
    "  \"guardrails\": [\n",
    "    \"presidio-pii\"\n",
    "  ]\n",
    "})\n",
    "headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'Content-Type': 'application/json'\n",
    "  \n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732966d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "client = openai.OpenAI(\n",
    "    api_key=\"anything\",\n",
    "    base_url=\"http://127.0.0.1:4000\"\n",
    ")\n",
    "\n",
    "# request sent to model set on litellm proxy, `litellm --model`\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"my name is rakesh email is rakesh@gmail.com  and phone number is 9030777879\"\n",
    "        }\n",
    "    ],\n",
    "    extra_body={ \n",
    "        \"metadata\": {\n",
    "            \"guardrails\": [\"presidio-pii\"],\n",
    "            \"guardrail_config\": {\"language\": \"es\"}\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddeb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://127.0.0.1:4000/apply_guardrail\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"guardrail_name\": \"presidio-pii\",\n",
    "  \"text\": \"My name is John Doe and my email is john@example.com and aadhar is 6373 4567 2345\",\n",
    "  \"language\": \"string\",\n",
    "  \"entities\": [\n",
    "    \"CREDIT_CARD\"\n",
    "  ]\n",
    "})\n",
    "headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai # openai v1.0.0+\n",
    "client = openai.OpenAI(base_url=\"http://127.0.0.1:4000\") # set proxy to base_url\n",
    "# request sent to model set on litellm proxy, `litellm --model`\n",
    "response = client.chat.completions.create(model=\"\", messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"this is a test request, write a very long  poem\"\n",
    "    }\n",
    "],\n",
    "stream=True,\n",
    ")\n",
    "\n",
    "# stream is an iterator of chunks/events\n",
    "for chunk in response:\n",
    "    # chunk is dict-like; content often at chunk.choices[0].delta.get(\"content\")\n",
    "    try:\n",
    "        delta = chunk.choices[0].delta\n",
    "        text = delta.get(\"content\") or delta.get(\"role\") or \"\"\n",
    "    except Exception:\n",
    "        text = getattr(chunk, \"text\", \"\") or str(chunk)\n",
    "    if text:\n",
    "        print(text, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ccab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://127.0.0.1:4000/guardrails/apply_guardrail\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"guardrail_name\": \"presidio-pii\",\n",
    "  \"text\": \"My name is John Doe and my email is john@example.com and ph no is 9030767789 adhar no is 1234 5678 9123 and credit card no is 4111 1111 1111 1111\",\n",
    "  \"language\": \"en\",\n",
    "  \"entities\": [\n",
    "    \"PERSON\",\n",
    "    \"EMAIL_ADDRESS\",\n",
    "    \"IN_AADHAAR\",\n",
    "    \"CREDIT_CARD\"\n",
    "  ]\n",
    "})\n",
    "headers = {\n",
    "  'Authorization': 'Bearer XXX',\n",
    "  'Content-Type': 'application/json',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
