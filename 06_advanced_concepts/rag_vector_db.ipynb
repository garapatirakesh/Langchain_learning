{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RAG (Retrieval-Augmented Generation) with Vector Databases\n",
                "\n",
                "## Introduction\n",
                "RAG is a technique that gives LLMs access to specific, up-to-date data without fine-tuning. It works by:\n",
                "1.  **Retrieving** relevant documents from a database.\n",
                "2.  **Augmenting** the user prompt with that context.\n",
                "3.  **Generating** a response using the augmented prompt.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup\n",
                "We need `langchain-chroma` and `langchain-openai` (or alternatives)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install -qU langchain-openai langchain-chroma langchain-community beautifulsoup4"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load and Split Documents\n",
                "We will load a webpage and split it into chunks so it fits into the LLM's context window."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_community.document_loaders import WebBaseLoader\n",
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "\n",
                "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
                "docs = loader.load()\n",
                "\n",
                "# Split into 1000 character chunks with 200 overlap\n",
                "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
                "splits = text_splitter.split_documents(docs)\n",
                "\n",
                "print(f\"Created {len(splits)} chunks from the document.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Indexing (Embeddings & VectorStore)\n",
                "We convert text into numbers (embeddings) and store them in a VectorDB (Chroma)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_chroma import Chroma\n",
                "from langchain_openai import OpenAIEmbeddings\n",
                "\n",
                "vectorstore = Chroma.from_documents(\n",
                "    documents=splits, \n",
                "    embedding=OpenAIEmbeddings(),\n",
                "    persist_directory=\"./chroma_db\"\n",
                ")\n",
                "\n",
                "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. The RAG Chain (using LCEL)\n",
                "We create a chain that takes a question, retrieves context, and formats it for the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.runnables import RunnablePassthrough\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "\n",
                "template = \"\"\"Answer the question based only on the following context:\n",
                "{context}\n",
                "\n",
                "Question: {question}\n",
                "\"\"\"\n",
                "prompt = ChatPromptTemplate.from_template(template)\n",
                "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
                "\n",
                "def format_docs(docs):\n",
                "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
                "\n",
                "rag_chain = (\n",
                "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
                "    | prompt\n",
                "    | llm\n",
                "    | StrOutputParser()\n",
                ")\n",
                "\n",
                "# result = rag_chain.invoke(\"What are the components of an LLM agent?\")\n",
                "# print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "1.  **Loading**: Get the raw data.\n",
                "2.  **Splitting**: Chunk it for memory efficiency.\n",
                "3.  **Embedding**: Convert text to math (vectors).\n",
                "4.  **Retrieval**: Find common semantic matches.\n",
                "5.  **Generation**: Let the LLM answer using the retrieved facts."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}